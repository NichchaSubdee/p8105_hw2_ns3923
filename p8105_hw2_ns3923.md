p8105_hw2_ns3923
================

**Setup necessary library**

``` r
library(tidyverse)
```

## Problem 1

Aims: Merging *pols-month.csv*, *unemployment.csv*, and *snp.csv* into a
dataframe by using year/month as keys variable

**Import data**

``` r
pols_df = read_csv(file = "./fivethirtyeight_datasets/pols-month.csv")
unemployment_df = read.csv(file = "./fivethirtyeight_datasets/unemployment.csv")
snp_df = read.csv(file = "./fivethirtyeight_datasets/snp.csv")
```

**Step 1**: Cleaning *pols-month.csv*

1.  Break up `mon` (e.g., 1/15/1947) into integer variables
    `year`,`month`, and `day`

2.  Replace month number with month name

3.  Create `president`: taking values `gop` and `dem`

4.  Remove `prez_dem` and `prez_gop`, and the day variable

``` r
pols_df = pols_df |>
    janitor::clean_names() |>
    separate(mon, into = c("month","day","year"), convert = TRUE) |>
    mutate(
      president = ifelse(prez_gop == 1, "gop", "dem"),   
      month = factor(month, levels = 1:12, labels = month.abb, ordered = TRUE)  
           ) |>
    select(year, month, president,
           starts_with("gov"),
           starts_with("sen"),
           starts_with("rep")) |>
    arrange(year, month)
#Result
pols_df
```

    ## # A tibble: 822 × 9
    ##     year month president gov_gop gov_dem sen_gop sen_dem rep_gop rep_dem
    ##    <int> <ord> <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>
    ##  1  1947 Jan   dem            23      23      51      45     253     198
    ##  2  1947 Feb   dem            23      23      51      45     253     198
    ##  3  1947 Mar   dem            23      23      51      45     253     198
    ##  4  1947 Apr   dem            23      23      51      45     253     198
    ##  5  1947 May   dem            23      23      51      45     253     198
    ##  6  1947 Jun   dem            23      23      51      45     253     198
    ##  7  1947 Jul   dem            23      23      51      45     253     198
    ##  8  1947 Aug   dem            23      23      51      45     253     198
    ##  9  1947 Sep   dem            23      23      51      45     253     198
    ## 10  1947 Oct   dem            23      23      51      45     253     198
    ## # ℹ 812 more rows

**Step 2**: Cleaning *snp.csv*

Using a similar process to pol-month.csv

``` r
snp_df = snp_df |>
    janitor::clean_names() |>
    separate(date, into = c("month","day","year"), convert = TRUE) |>
    mutate(
        month = factor(month, levels = 1:12, labels = month.abb, ordered = TRUE)
      ) |>
    select(year, month, close) |>
    arrange(year, month)

#Result
head(snp_df, 10)
```

    ##    year month close
    ## 1  1950   Jan 17.05
    ## 2  1950   Feb 17.22
    ## 3  1950   Mar 17.29
    ## 4  1950   Apr 17.96
    ## 5  1950   May 18.78
    ## 6  1950   Jun 17.69
    ## 7  1950   Jul 17.84
    ## 8  1950   Aug 18.42
    ## 9  1950   Sep 19.45
    ## 10 1950   Oct 19.53

**Step 3**: Tidy *unemployment.csv*

1.  Switching from “wide” to “long” format

2.  Ensuring that key variables have the same name and take the same
    values.

``` r
unemployment_df = unemployment_df |>
    janitor::clean_names() |>
    pivot_longer(jan:dec, names_to = "month", values_to = "unemployment") |>
    mutate(month = factor(stringr::str_to_title(month),
           levels = month.abb, ordered = TRUE)) |>
    select(year, month, unemployment) |>
    arrange(year, month)

# show first 10 rows
head(unemployment_df, 10)
```

    ## # A tibble: 10 × 3
    ##     year month unemployment
    ##    <int> <ord>        <dbl>
    ##  1  1948 Jan            3.4
    ##  2  1948 Feb            3.8
    ##  3  1948 Mar            4  
    ##  4  1948 Apr            3.9
    ##  5  1948 May            3.5
    ##  6  1948 Jun            3.6
    ##  7  1948 Jul            3.6
    ##  8  1948 Aug            3.9
    ##  9  1948 Sep            3.8
    ## 10  1948 Oct            3.7

**Step 4**: Joining these 3 cleaned dataset

- Merging `snp` into `pols` and merging `unemployment` into the result.

``` r
Final_df = pols_df |>
    left_join(snp_df,  by = c("year","month")) |>
    left_join(unemployment_df, by = c("year","month")) |>
    arrange(year, month)

#Result
Final_df
```

    ## # A tibble: 822 × 11
    ##     year month president gov_gop gov_dem sen_gop sen_dem rep_gop rep_dem close
    ##    <int> <ord> <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>
    ##  1  1947 Jan   dem            23      23      51      45     253     198    NA
    ##  2  1947 Feb   dem            23      23      51      45     253     198    NA
    ##  3  1947 Mar   dem            23      23      51      45     253     198    NA
    ##  4  1947 Apr   dem            23      23      51      45     253     198    NA
    ##  5  1947 May   dem            23      23      51      45     253     198    NA
    ##  6  1947 Jun   dem            23      23      51      45     253     198    NA
    ##  7  1947 Jul   dem            23      23      51      45     253     198    NA
    ##  8  1947 Aug   dem            23      23      51      45     253     198    NA
    ##  9  1947 Sep   dem            23      23      51      45     253     198    NA
    ## 10  1947 Oct   dem            23      23      51      45     253     198    NA
    ## # ℹ 812 more rows
    ## # ℹ 1 more variable: unemployment <dbl>

**Description**: The cleaned *pols_df* dataset \[822 rows x 9
variables\] contains counts of governors (`gov_dem` or `gov_gop`),
senators (`sen_dem` or `sen_gop`), and representatives (`rep_dem` or
`rep_gop`) by party(i.e., Democratic and Republican) and the party of
the sitting president (`president`). Also, the cleaned *snp_df* dataset
\[787 rows x 3 variables\] contains the S&P monthly closing value
(`close`). Lastly, *unemployment_df* \[816 rows x 3 variables\] has the
monthly unemployment rate (`unemployment`). After combining these three
datasets by using `month` and `year` as key variables, the *Final_df*
has 822 rows and 11 variables, starting from January 1947 to June 2015.

## Problem 2

The *Mr. Trash Wheel* dataset consists of 6 sheets, and the sheets that
will be used in this problem are *Mr. Trash Wheel*,*Professor Trash
Wheel*, and *Gwynnda Trash Wheel*.

**Setup necessary library**

``` r
library(readxl)
```

Before I import the excel file, I change its name in the local folder to
*TrashWheel_data*

**Import data**

``` r
MrTrash_df = read_excel("./TrashWheel_data.xlsx", sheet = "Mr. Trash Wheel", skip = 1)
ProfTrash_df = read_excel("./TrashWheel_data.xlsx", sheet = "Professor Trash Wheel", skip = 1)
Gwyn_df = read_excel("./TrashWheel_data.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1)
```

**Mr. Trash Wheel cleaning**

``` r
MrTrash_df = MrTrash_df |>
    janitor::clean_names() |>
    janitor::remove_empty("cols") |> 
    select(-starts_with("...")) |>
    filter(!is.na(dumpster)) |> 
    mutate(
      sports_balls = as.integer(round(sports_balls)),
      wheel = "Mr. Trash Wheel",
      year = as.integer(year)
    )

#Result
MrTrash_df
```

    ## # A tibble: 651 × 15
    ##    dumpster month  year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <int> <dttm>                    <dbl>              <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # ℹ 641 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>, wheel <chr>

**Professor Trash Wheel Cleaning**

``` r
ProfTrash_df = ProfTrash_df |> 
    janitor::clean_names() |> 
    janitor::remove_empty("cols") |> 
    filter(!is.na(dumpster)) |> 
    mutate(
      wheel = "Professor Trash Wheel",
      year = as.integer(year)
    )

#Result
ProfTrash_df
```

    ## # A tibble: 119 × 14
    ##    dumpster month     year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <int> <dttm>                    <dbl>              <dbl>
    ##  1        1 January   2017 2017-01-02 00:00:00        1.79                 15
    ##  2        2 January   2017 2017-01-30 00:00:00        1.58                 15
    ##  3        3 February  2017 2017-02-26 00:00:00        2.32                 18
    ##  4        4 February  2017 2017-02-26 00:00:00        3.72                 15
    ##  5        5 February  2017 2017-02-28 00:00:00        1.45                 15
    ##  6        6 March     2017 2017-03-30 00:00:00        1.71                 15
    ##  7        7 April     2017 2017-04-01 00:00:00        1.82                 15
    ##  8        8 April     2017 2017-04-20 00:00:00        2.37                 15
    ##  9        9 May       2017 2017-05-10 00:00:00        2.64                 15
    ## 10       10 May       2017 2017-05-26 00:00:00        2.78                 15
    ## # ℹ 109 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>, wheel <chr>

**Gwynnda Trash Wheel Cleaning**

``` r
Gwyn_df = Gwyn_df |> 
    janitor::clean_names() |> 
    janitor::remove_empty("cols") |> 
    filter(!is.na(dumpster)) |> 
    mutate(
      wheel = "Gwynnda Trash Wheel",
      year = as.integer(year)
    )

#Result
Gwyn_df
```

    ## # A tibble: 263 × 13
    ##    dumpster month   year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>  <int> <dttm>                    <dbl>              <dbl>
    ##  1        1 July    2021 2021-07-03 00:00:00        0.93                 15
    ##  2        2 July    2021 2021-07-07 00:00:00        2.26                 15
    ##  3        3 July    2021 2021-07-07 00:00:00        1.62                 15
    ##  4        4 July    2021 2021-07-16 00:00:00        1.76                 15
    ##  5        5 July    2021 2021-07-30 00:00:00        1.53                 15
    ##  6        6 August  2021 2021-08-11 00:00:00        2.06                 15
    ##  7        7 August  2021 2021-08-14 00:00:00        1.9                  15
    ##  8        8 August  2021 2021-08-16 00:00:00        2.16                 15
    ##  9        9 August  2021 2021-08-16 00:00:00        2.6                  15
    ## 10       10 August  2021 2021-08-17 00:00:00        3.21                 15
    ## # ℹ 253 more rows
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>, wheel <chr>

**Combine all three sheets**

``` r
FinalTrash_df =
    bind_rows(MrTrash_df, ProfTrash_df, Gwyn_df) |> 
    mutate(
      year = as.integer(year),
      month = factor(month, levels = month.name, ordered = TRUE)
    ) |> 
    relocate(wheel, dumpster, date, year, month)

#Result
FinalTrash_df
```

    ## # A tibble: 1,033 × 15
    ##    wheel dumpster date                 year month weight_tons volume_cubic_yards
    ##    <chr>    <dbl> <dttm>              <int> <ord>       <dbl>              <dbl>
    ##  1 Mr. …        1 2014-05-16 00:00:00  2014 May          4.31                 18
    ##  2 Mr. …        2 2014-05-16 00:00:00  2014 May          2.74                 13
    ##  3 Mr. …        3 2014-05-16 00:00:00  2014 May          3.45                 15
    ##  4 Mr. …        4 2014-05-17 00:00:00  2014 May          3.1                  15
    ##  5 Mr. …        5 2014-05-17 00:00:00  2014 May          4.06                 18
    ##  6 Mr. …        6 2014-05-20 00:00:00  2014 May          2.71                 13
    ##  7 Mr. …        7 2014-05-21 00:00:00  2014 May          1.91                  8
    ##  8 Mr. …        8 2014-05-28 00:00:00  2014 May          3.7                  16
    ##  9 Mr. …        9 2014-06-05 00:00:00  2014 June         2.52                 14
    ## 10 Mr. …       10 2014-06-11 00:00:00  2014 June         3.76                 18
    ## # ℹ 1,023 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>

**Description**: I imported the *Mr. Trash Wheel*, *Professor Trash
Wheel*, and *Gwynnda Trash Wheel* sheets, cleaned names, and removed
unnecessary columns and rows with missing `dumpster`. Then, I created a
new variable called `wheel` and stacked the three datasets. The final
dataset, *FinalTrash_df*, has 1033 observations and 15 variables. Some
key variables include `dumpster`, `weight_tons`, and types of trash like
`sports_balls`, `plastic_bottles`, and `cigarette_butts`.

From the available data, Professor Trash Wheel collected 246.74 tons in
total, and Gwynnda collected 18,120 cigarette butts in June 2022.

## Problem 3

Aims: To combine an organized dataset of *zillow_data*

**Import data**

``` r
zip_df = read_csv(file = "./zillow_data/Zip Codes.csv")
zori_df = read.csv(file = "./zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv")
```

**Step 1: Clean ZIP crosswalk**

``` r
zip_df = zip_df |> 
    janitor::clean_names() |> 
    rename(zip = zip_code) |> 
    mutate(
      zip = stringr::str_pad(as.character(zip), 5, pad = "0"),
      borough = case_when(
        county == "New York" ~ "Manhattan",
        county == "Kings" ~ "Brooklyn",
        county == "Queens" ~ "Queens",
        county == "Bronx" ~ "Bronx",
        county == "Richmond" ~ "Staten Island",
        TRUE ~ county
        )) |> 
  distinct(zip, borough, county, neighborhood) |> 
  arrange(zip)

#Result
head(zip_df, 10)
```

    ## # A tibble: 10 × 4
    ##    zip   borough   county   neighborhood                 
    ##    <chr> <chr>     <chr>    <chr>                        
    ##  1 10001 Manhattan New York Chelsea and Clinton          
    ##  2 10002 Manhattan New York Lower East Side              
    ##  3 10003 Manhattan New York Lower East Side              
    ##  4 10004 Manhattan New York Lower Manhattan              
    ##  5 10005 Manhattan New York Lower Manhattan              
    ##  6 10006 Manhattan New York Lower Manhattan              
    ##  7 10007 Manhattan New York Lower Manhattan              
    ##  8 10008 Manhattan New York <NA>                         
    ##  9 10009 Manhattan New York Lower East Side              
    ## 10 10010 Manhattan New York Gramercy Park and Murray Hill

**Step 2: Tidy the zillow_zori file**

Wide to long format

``` r
zori_df = zori_df |>
    janitor::clean_names() |>
    rename(zip = region_name) |>
    mutate(zip = str_pad(as.character(zip), 5, pad = "0")) |>

    pivot_longer(
      cols = matches("^x\\d{4}(_\\d{2}){2}$"),
      names_to  = "date_str",
      values_to = "zori"
      ) |>
    mutate(
      date = ymd(
      str_replace_all(str_remove(date_str, "^x"), "_", "-")
      )
  ) |>
  
  select(zip, date, zori) |>
  arrange(zip, date)

#Result
head(zori_df, 10)
```

    ## # A tibble: 10 × 3
    ##    zip   date        zori
    ##    <chr> <date>     <dbl>
    ##  1 10001 2015-01-31 3855.
    ##  2 10001 2015-02-28 3892.
    ##  3 10001 2015-03-31 3898.
    ##  4 10001 2015-04-30 3970.
    ##  5 10001 2015-05-31 4033.
    ##  6 10001 2015-06-30 4071.
    ##  7 10001 2015-07-31 4067.
    ##  8 10001 2015-08-31 4070.
    ##  9 10001 2015-09-30 4040.
    ## 10 10001 2015-10-31 4023.

**Step 3: Merge tidy ZORI with the ZIP crosswalk**

``` r
zip_unique = zip_df |> 
    group_by(zip) |> 
    slice(1) |> 
    ungroup()

nyc_rent = zori_df |> 
    left_join(zip_unique, by = "zip") |> 
    relocate(zip, borough, county, neighborhood, date, zori) |> 
  arrange(zip, date)

#Result
nyc_rent
```

    ## # A tibble: 17,284 × 6
    ##    zip   borough   county   neighborhood        date        zori
    ##    <chr> <chr>     <chr>    <chr>               <date>     <dbl>
    ##  1 10001 Manhattan New York Chelsea and Clinton 2015-01-31 3855.
    ##  2 10001 Manhattan New York Chelsea and Clinton 2015-02-28 3892.
    ##  3 10001 Manhattan New York Chelsea and Clinton 2015-03-31 3898.
    ##  4 10001 Manhattan New York Chelsea and Clinton 2015-04-30 3970.
    ##  5 10001 Manhattan New York Chelsea and Clinton 2015-05-31 4033.
    ##  6 10001 Manhattan New York Chelsea and Clinton 2015-06-30 4071.
    ##  7 10001 Manhattan New York Chelsea and Clinton 2015-07-31 4067.
    ##  8 10001 Manhattan New York Chelsea and Clinton 2015-08-31 4070.
    ##  9 10001 Manhattan New York Chelsea and Clinton 2015-09-30 4040.
    ## 10 10001 Manhattan New York Chelsea and Clinton 2015-10-31 4023.
    ## # ℹ 17,274 more rows

``` r
#Observations, unique ZIP, unique neighborhood
n_obs = nrow(nyc_rent)
n_zip = n_distinct(nyc_rent$zip)
n_neighborhood = nyc_rent |> 
    filter(!is.na(neighborhood)) |>
    pull(neighborhood) |> 
    n_distinct()

#Zip code in ZIP dataset, not in Zillow dataset
zips_not_zori = anti_join(
    zip_unique,
    distinct(zori_df, zip), by = "zip"
    ) |> 
    arrange(zip)
```

# **Description**:

**How many total observations exist?**

The final dataset, `nyc_rent`, has 17,284 observations

**How many unique ZIP codes are included, and how many unique
neighborhoods?**: There are 149 unique ZIP codes and 42 neighborhoods.

**Which ZIP codes appear in the ZIP code dataset but not in the Zillow
Rental Price dataset? Why?**:

There are 171 ZIP codes that appear in the crosswalk but not in the
Zillow Rental Price dataset. These are often specific purpose or
non-residential ZIPs (e.g., PO boxes or commercial-only areas), or
places with too little rental activity for Zillow to publish a series. A
few examples are shown below:

``` r
zips_not_zori |> 
    select(zip, borough, neighborhood) |> 
    slice_head(n = 10) |> 
knitr::kable(caption = "**Table 1:** ZIP codes present in the crosswalk but missing in ZORI")
```

| zip   | borough   | neighborhood        |
|:------|:----------|:--------------------|
| 10008 | Manhattan | NA                  |
| 10020 | Manhattan | Chelsea and Clinton |
| 10041 | Manhattan | NA                  |
| 10043 | Manhattan | NA                  |
| 10045 | Manhattan | NA                  |
| 10047 | Manhattan | NA                  |
| 10048 | Manhattan | NA                  |
| 10055 | Manhattan | NA                  |
| 10072 | Manhattan | NA                  |
| 10080 | Manhattan | NA                  |

**Table 1:** ZIP codes present in the crosswalk but missing in ZORI

**Rental prices fluctuated dramatically during the COVID-19 pandemic.
For all available ZIP codes, compare rental prices in January 2021 to
prices in January 2020. Make a table that shows the 10 ZIP codes (along
with the borough and neighborhood) with largest drop in price from
January 2020 to 2021.**

The Table below lists the 10 ZIP codes with the largest drops in ZORI
from January 2020 to January 2021

``` r
#COVID
covid_drop =
    nyc_rent |>
    filter(date %in% as.Date(c("2020-01-31", "2021-01-31"))) |>
    mutate(year = lubridate::year(date)) |>
    select(zip, borough, neighborhood, year, zori) |>
    pivot_wider(names_from = year, values_from = zori, names_prefix = "y")     |>
    mutate(drop_2020_2021 = y2021 - y2020) |>
    arrange(drop_2020_2021) |>
    slice_head(n = 10)

#Result
knitr::kable(covid_drop, digits = 0, caption = "**Table 2:** Largest drops in ZORI from January 2020 to January 2021")
```

| zip   | borough   | neighborhood                  | y2020 | y2021 | drop_2020_2021 |
|:------|:----------|:------------------------------|------:|------:|---------------:|
| 10007 | Manhattan | Lower Manhattan               |  6334 |  5422 |           -913 |
| 10069 | Manhattan | NA                            |  4623 |  3875 |           -748 |
| 10009 | Manhattan | Lower East Side               |  3406 |  2692 |           -714 |
| 10016 | Manhattan | Gramercy Park and Murray Hill |  3731 |  3019 |           -712 |
| 10001 | Manhattan | Chelsea and Clinton           |  4108 |  3398 |           -710 |
| 10002 | Manhattan | Lower East Side               |  3645 |  2935 |           -710 |
| 10004 | Manhattan | Lower Manhattan               |  3150 |  2444 |           -706 |
| 10038 | Manhattan | Lower Manhattan               |  3573 |  2876 |           -698 |
| 10012 | Manhattan | Greenwich Village and Soho    |  3629 |  2942 |           -686 |
| 10010 | Manhattan | Gramercy Park and Murray Hill |  3697 |  3012 |           -685 |

**Table 2:** Largest drops in ZORI from January 2020 to January 2021

From Table 2, the biggest declines are concentrated in Manhattan ZIP
codes, which fits the early-pandemic pattern of renters leaving dense,
high-cost areas. Negative values indicate that rents fell
year-over-year.
