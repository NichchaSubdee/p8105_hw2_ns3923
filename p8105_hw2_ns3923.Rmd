---
title: "p8105_hw2_ns3923"
Name: Nichcha Subdee (ns3923)
output: github_document
---

**Setup necessary library**
```{r setup, message=FALSE}
library(tidyverse)
```

## Problem 1
Aims: Merging *pols-month.csv*, *unemployment.csv*, and *snp.csv* into a dataframe by using year/month as keys variable

**Import data**
```{r import data, message=FALSE}
pols_df = read_csv(file = "./fivethirtyeight_datasets/pols-month.csv")
unemployment_df = read.csv(file = "./fivethirtyeight_datasets/unemployment.csv")
snp_df = read.csv(file = "./fivethirtyeight_datasets/snp.csv")
```

**Step 1**: Cleaning *pols-month.csv*

1. Break up `mon` (e.g., 1/15/1947) into integer variables `year`,`month`, and `day`

2. Replace month number with month name

3. Create `president`: taking values `gop` and `dem`

4. Remove `prez_dem` and `prez_gop`, and the day variable
```{r pols-month_dataset}
pols_df = pols_df |>
    janitor::clean_names() |>
    separate(mon, into = c("month","day","year"), convert = TRUE) |>
    mutate(
      president = ifelse(prez_gop == 1, "gop", "dem"),   
      month = factor(month, levels = 1:12, labels = month.abb, ordered = TRUE)  
           ) |>
    select(year, month, president,
           starts_with("gov"),
           starts_with("sen"),
           starts_with("rep")) |>
    arrange(year, month)
#Result
pols_df
```

**Step 2**: Cleaning *snp.csv* 

Using a similar process to pol-month.csv

```{r snp_dataset}
snp_df = snp_df |>
    janitor::clean_names() |>
    separate(date, into = c("month","day","year"), convert = TRUE) |>
    mutate(
        month = factor(month, levels = 1:12, labels = month.abb, ordered = TRUE)
      ) |>
    select(year, month, close) |>
    arrange(year, month)

#Result
head(snp_df, 10)
```

**Step 3**: Tidy *unemployment.csv* 

1. Switching from “wide” to “long” format

2. Ensuring that key variables have the same name and take the same values.

```{r unemployment_dataset}
unemployment_df = unemployment_df |>
    janitor::clean_names() |>
    pivot_longer(jan:dec, names_to = "month", values_to = "unemployment") |>
    mutate(month = factor(stringr::str_to_title(month),
           levels = month.abb, ordered = TRUE)) |>
    select(year, month, unemployment) |>
    arrange(year, month)

# show first 10 rows
head(unemployment_df, 10)
```

**Step 4**: Joining these 3 cleaned dataset

- Merging `snp` into `pols` and merging `unemployment` into the result.

```{r Final_df}
Final_df = pols_df |>
    left_join(snp_df,  by = c("year","month")) |>
    left_join(unemployment_df, by = c("year","month")) |>
    arrange(year, month)

#Result
Final_df
```

**Description**: 
The cleaned *pols_df* dataset [822 rows x 9 variables] contains counts of governors (`gov_dem` or `gov_gop`), senators (`sen_dem` or `sen_gop`), and representatives (`rep_dem` or `rep_gop`) by party(i.e., Democratic and Republican) and the party of the sitting president (`president`). Also, the cleaned *snp_df* dataset [787 rows x 3 variables] contains the S&P monthly closing value (`close`). Lastly, *unemployment_df* [816 rows x 3 variables] has the monthly unemployment rate (`unemployment`). After combining these three datasets by using `month` and `year` as key variables, the *Final_df* has `r nrow(Final_df)` rows and `r ncol(Final_df)` variables, starting from January 1947 to June 2015.


## Problem 2

The *Mr. Trash Wheel* dataset consists of 6 sheets, and the sheets that will be used in this problem are *Mr. Trash Wheel*,*Professor Trash Wheel*, and *Gwynnda Trash Wheel*.

**Setup necessary library**
```{r setup_P2, message=FALSE}
library(readxl)
```

Before I import the excel file, I change its name in the local folder to *TrashWheel_data*

**Import data**
```{r import data_P2, message=FALSE}
MrTrash_df = read_excel("./TrashWheel_data.xlsx", sheet = "Mr. Trash Wheel", skip = 1)
ProfTrash_df = read_excel("./TrashWheel_data.xlsx", sheet = "Professor Trash Wheel", skip = 1)
Gwyn_df = read_excel("./TrashWheel_data.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1)
```

**Mr. Trash Wheel cleaning**

```{r MrTrash_dataset}
MrTrash_df = MrTrash_df |>
    janitor::clean_names() |>
    janitor::remove_empty("cols") |> 
    select(-starts_with("...")) |>
    filter(!is.na(dumpster)) |> 
    mutate(
      sports_balls = as.integer(round(sports_balls)),
      wheel = "Mr. Trash Wheel",
      year = as.integer(year)
    )

#Result
MrTrash_df
```

**Professor Trash Wheel Cleaning**
```{r ProfTrash_dataset}
ProfTrash_df = ProfTrash_df |> 
    janitor::clean_names() |> 
    janitor::remove_empty("cols") |> 
    filter(!is.na(dumpster)) |> 
    mutate(
      wheel = "Professor Trash Wheel",
      year = as.integer(year)
    )

#Result
ProfTrash_df
```

**Gwynnda Trash Wheel Cleaning**
```{r GwynndaTrash_dataset}
Gwyn_df = Gwyn_df |> 
    janitor::clean_names() |> 
    janitor::remove_empty("cols") |> 
    filter(!is.na(dumpster)) |> 
    mutate(
      wheel = "Gwynnda Trash Wheel",
      year = as.integer(year)
    )

#Result
Gwyn_df
```

**Combine all three sheets**
```{r}
FinalTrash_df =
    bind_rows(MrTrash_df, ProfTrash_df, Gwyn_df) |> 
    mutate(
      year = as.integer(year),
      month = factor(month, levels = month.name, ordered = TRUE)
    ) |> 
    relocate(wheel, dumpster, date, year, month)

#Result
FinalTrash_df
```

**Description**:
I imported the *Mr. Trash Wheel*, *Professor Trash Wheel*, and *Gwynnda Trash Wheel* sheets, cleaned names, and removed unnecessary columns and rows with missing `dumpster`. Then, I created a new variable called `wheel` and stacked the three datasets. The final dataset, *FinalTrash_df*, has `r nrow(FinalTrash_df)` observations and `r ncol(FinalTrash_df)` variables. Some key variables include `dumpster`, `weight_tons`, and types of trash like `sports_balls`, `plastic_bottles`, and `cigarette_butts`.

From the available data, Professor Trash Wheel collected `r sum(ProfTrash_df$weight_tons, na.rm = TRUE)` tons in total, and Gwynnda collected `r format(as.integer(sum(Gwyn_df$cigarette_butts[Gwyn_df$year == 2022 & Gwyn_df$month == "June"], na.rm = TRUE)), big.mark = ",")` cigarette butts in June 2022. 


## Problem 3

Aims: To combine an organized dataset of *zillow_data*

**Import data**
```{r import data_P3, message=FALSE}
zip_df = read_csv(file = "./zillow_data/Zip Codes.csv")
zori_df = read.csv(file = "./zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv")
```

**Step 1: Clean ZIP crosswalk**
```{r zip_df}
zip_df = zip_df |> 
    janitor::clean_names() |> 
    rename(zip = zip_code) |> 
    mutate(
      zip = stringr::str_pad(as.character(zip), 5, pad = "0"),
      borough = case_when(
        county == "New York" ~ "Manhattan",
        county == "Kings" ~ "Brooklyn",
        county == "Queens" ~ "Queens",
        county == "Bronx" ~ "Bronx",
        county == "Richmond" ~ "Staten Island",
        TRUE ~ county
        )) |> 
  distinct(zip, borough, county, neighborhood) |> 
  arrange(zip)

#Result
head(zip_df, 10)
```

**Step 2: Tidy the zillow_zori file**

Wide to long format

```{r zori_df}
zori_df = zori_df |>
    janitor::clean_names() |>
    rename(zip = region_name) |>
    mutate(zip = str_pad(as.character(zip), 5, pad = "0")) |>

    pivot_longer(
      cols = matches("^x\\d{4}(_\\d{2}){2}$"),
      names_to  = "date_str",
      values_to = "zori"
      ) |>
    mutate(
      date = lubridate::ymd(
      stringr::str_replace_all(stringr::str_remove(date_str, "^x"), "_", "-")
      )
  ) |>
  
  select(zip, date, zori) |>
  arrange(zip, date)

#Result
head(zori_df, 10)
```

**Step 3: Merge tidy ZORI with the ZIP crosswalk**
```{r merge_P3}
zip_unique = zip_df |> 
    group_by(zip) |> 
    slice(1) |> 
    ungroup()

nyc_rent = zori_df |> 
    left_join(zip_unique, by = "zip") |> 
    relocate(zip, borough, county, neighborhood, date, zori) |> 
  arrange(zip, date)

#Result
nyc_rent
```

```{r P3_summary, message=FALSE}
#Observations, unique ZIP, unique neighborhood
n_obs = nrow(nyc_rent)
n_zip = n_distinct(nyc_rent$zip)
n_neighborhood = nyc_rent |> 
    filter(!is.na(neighborhood)) |>
    pull(neighborhood) |> 
    n_distinct()

#Zip code in ZIP dataset, not in Zillow dataset
zips_not_zori = anti_join(
    zip_unique,
    distinct(zori_df, zip), by = "zip"
    ) |> 
    arrange(zip)
```


# **Description**:

**How many total observations exist?**

The final dataset, `nyc_rent`, has `r format(n_obs, big.mark = ",")` observations.

**How many unique ZIP codes are included, and how many unique neighborhoods?**

There are `r n_zip` unique ZIP codes and `r n_neighborhood` neighborhoods.

**Which ZIP codes appear in the ZIP code dataset but not in the Zillow Rental Price dataset? Why?**: 

There are `r nrow(zips_not_zori)` ZIP codes that appear in the crosswalk but not in the Zillow Rental Price dataset. These are often specific purpose or non-residential ZIPs (e.g., PO boxes or commercial-only areas or low-activity ZIPs), or places with too little rental activity for Zillow to publish a series. A few examples are shown below: 
```{r zip_notZillow}
zips_not_zori |> 
    select(zip, borough, neighborhood) |> 
    slice_head(n = 10) |> 
knitr::kable(caption = "**Table 1:** ZIP codes present in the crosswalk but missing in ZORI")
```


**Rental prices fluctuated dramatically during the COVID-19 pandemic. For all available ZIP codes, compare rental prices in January 2021 to prices in January 2020. Make a table that shows the 10 ZIP codes (along with the borough and neighborhood) with largest drop in price from January 2020 to 2021.**

The Table below lists the 10 ZIP codes with the largest drops in ZORI from January 2020 to January 2021
```{r covid_P3}
#COVID
covid_drop =
    nyc_rent |>
    filter(date %in% as.Date(c("2020-01-31", "2021-01-31"))) |>
    mutate(year = lubridate::year(date)) |>
    select(zip, borough, neighborhood, year, zori) |>
    pivot_wider(names_from = year, values_from = zori, names_prefix = "y")     |>
    mutate(drop_2020_2021 = y2021 - y2020) |>
    arrange(drop_2020_2021) |>
    slice_head(n = 10)

#Result
knitr::kable(covid_drop, digits = 0, caption = "**Table 2:** Largest drops in ZORI from January 2020 to January 2021")
```

From Table 2, the biggest declines are concentrated in Manhattan ZIP codes, which fits the early-pandemic pattern of renters leaving dense, high-cost areas. Negative values indicate that rents fell year-over-year.

